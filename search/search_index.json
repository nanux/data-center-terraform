{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Infrastructure for Atlassian Data Center products on Kubernetes \u00b6 Atlassian DC Apps program provides App vendors in Atlassian ecosystem with tools to setup ready-to-use environment. This project provides a tool to provision infrastructure for Atlassian DC helm chart products. At this stage the scope is providing the infrastructure for Bamboo DC. Prerequisites \u00b6 In order to deploy the infrastructure for Atlassian Data Center products on Kubernetes you need to have the following applications installed on your local machine: AWS CLI helm Terraform See prerequisites for details. Installation \u00b6 Before installing the infrastructure for Atlassian products, please make sure you read the prerequisites section and completed the configuration . After you have done the above steps you can install the Atlassian Data Center infrastructure for selected products. Uninstall the products and infrastructure \u00b6 In installation process, Terraform created all required resources on AWS environment in order to provide the infrastructure to handle Atlassian Data Center products. If you want to uninstall all products and cleanup the infrastructure see cleanup page . Feedback \u00b6 If you find any issue, raise a ticket . If you have general feedback or question regarding the project, use Atlassian Community Kubernetes space . Contributions \u00b6 Contributions are welcome! Find out how to contribute . License \u00b6 Copyright (c) [2021] Atlassian and others. Apache 2.0 licensed, see LICENSE file.","title":"Home"},{"location":"#infrastructure-for-atlassian-data-center-products-on-kubernetes","text":"Atlassian DC Apps program provides App vendors in Atlassian ecosystem with tools to setup ready-to-use environment. This project provides a tool to provision infrastructure for Atlassian DC helm chart products. At this stage the scope is providing the infrastructure for Bamboo DC.","title":"Infrastructure for Atlassian Data Center products on Kubernetes"},{"location":"#prerequisites","text":"In order to deploy the infrastructure for Atlassian Data Center products on Kubernetes you need to have the following applications installed on your local machine: AWS CLI helm Terraform See prerequisites for details.","title":"Prerequisites"},{"location":"#installation","text":"Before installing the infrastructure for Atlassian products, please make sure you read the prerequisites section and completed the configuration . After you have done the above steps you can install the Atlassian Data Center infrastructure for selected products.","title":"Installation"},{"location":"#uninstall-the-products-and-infrastructure","text":"In installation process, Terraform created all required resources on AWS environment in order to provide the infrastructure to handle Atlassian Data Center products. If you want to uninstall all products and cleanup the infrastructure see cleanup page .","title":"Uninstall the products and infrastructure"},{"location":"#feedback","text":"If you find any issue, raise a ticket . If you have general feedback or question regarding the project, use Atlassian Community Kubernetes space .","title":"Feedback"},{"location":"#contributions","text":"Contributions are welcome! Find out how to contribute .","title":"Contributions"},{"location":"#license","text":"Copyright (c) [2021] Atlassian and others. Apache 2.0 licensed, see LICENSE file.","title":"License"},{"location":"development/HOW_ADD_PRODUCT/","text":"How to add product \u00b6","title":"How to add product"},{"location":"development/HOW_ADD_PRODUCT/#how-to-add-product","text":"","title":"How to add product"},{"location":"development/HOW_TO_START/","text":"How to start development \u00b6 Codebase \u00b6 You can find the repo here: Data Center Terraform . Please clone the repo to your local: git clone git@github.com:atlassian-labs/data-center-terraform.git Requirements: \u00b6 Make sure you have installed the following tools, if not, install them: Terraform brew install hashicorp/tap/terraform Helm brew install helm AWS CLI Github Pre-commit hook \u00b6 Install pre-commit . E.g. brew install pre-commit Run pre-commit install in the repository. Install tflint . E.g. brew install tflint Add the following content into .tflint.hcl : plugin \"aws\" { enabled = true version = \"0.5.0\" source = \"github.com/terraform-linters/tflint-ruleset-aws\" } run the following command: tflint --init","title":"How to start development"},{"location":"development/HOW_TO_START/#how-to-start-development","text":"","title":"How to start development"},{"location":"development/HOW_TO_START/#codebase","text":"You can find the repo here: Data Center Terraform . Please clone the repo to your local: git clone git@github.com:atlassian-labs/data-center-terraform.git","title":"Codebase"},{"location":"development/HOW_TO_START/#requirements","text":"Make sure you have installed the following tools, if not, install them: Terraform brew install hashicorp/tap/terraform Helm brew install helm AWS CLI","title":"Requirements:"},{"location":"development/HOW_TO_START/#github-pre-commit-hook","text":"Install pre-commit . E.g. brew install pre-commit Run pre-commit install in the repository. Install tflint . E.g. brew install tflint Add the following content into .tflint.hcl : plugin \"aws\" { enabled = true version = \"0.5.0\" source = \"github.com/terraform-linters/tflint-ruleset-aws\" } run the following command: tflint --init","title":"Github Pre-commit hook"},{"location":"development/HOW_TO_TEST/","text":"Testing \u00b6 Structure \u00b6 You can find tests in /test . * unittest includes module level terraform plan validation test. It is required to implement the unit tests for each module. Make sure each test case covers default, customised and invalid conditions. * e2etest contains the end-to-end tests for infrastructure and products. It will follow the entire deployment process including provisioning resources into a cloud provider. Each product will have one test function that covers all the states. The test function starts with generating configuration for the terratest , helm , kubectl commands. You can change config variables as you like in the GenerateConfigForProductE2eTest() function. The provisioning process will be as follows: 1. Create AWS resources using Terraform 2. Create EKS namespace (product name by default) 3. Helm adds Atlassian helm chart repository and install specified product Once the cluster and product are initialised, assert functions will validate the terraform outputs. bamboo_test.go file will only test the resource creation and validation : You must run cleanup_test.go to test the destruction! Requirements: \u00b6 The repo uses Terratest for testing. The following are required to run the test: 1. install Terraform . E.g. brew install hashicorp/tap/terraform 2. install Go . E.g. brew install go 3. Set credentials to connect to cloud provider. The project looks for ~/.aws . For more details refer to AWS cli-configure-quickstart . How to run unit test \u00b6 cd test && go get -v -t -d ./... && go mod tidy go test ./unittest/... -v You can run test with regex keyword to run specific group of test cases e.g. Running only VPC module related tests go test./unittest/... -v -run TestVpc How to run end-to-end test (approx. 40-60 mins) \u00b6 cd test && mkdir ./e2etest/artifacts go get -v -t -d ./... && go mod tidy go test ./e2etest -v -timeout 40m -run Bamboo | tee ./e2etest/artifacts/e2e-test.log Clean up test go test ./e2etest -v -timeout 40m -run Cleanup | tee ./e2etest/artifacts/e2e-test-cleanup.log How to reuse end-to-end test environment \u00b6 When you run end-to-end test for the first time, the test function will create an environment config file under /test/e2etest/artifacts folder (the default file name is e2e_test_env_config.json ). This config file allows you to reuse the existing terraform environment directory created by terratest. You can specify the config file name on the second run and the function will load the config data and reuse the existing environment. e.g. go test ./e2etest -v -timeout 40m -run Bamboo -config=e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test.log You can do the same for the cleanup test. e.g. go test ./e2etest -v -timeout 40m -run Cleanup -config=e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test-cleanup.log If -config flag is not specified, the second test will create a new test environment and overwrite e2e_test_env_config.json if existed So make sure you rename e2e_test_env_config.json to avoid accidental overwrites. GitHub Action \u00b6 GitHub action will run for unit and end-to-end tests. Config file is in .github/workflows","title":"Testing"},{"location":"development/HOW_TO_TEST/#testing","text":"","title":"Testing"},{"location":"development/HOW_TO_TEST/#structure","text":"You can find tests in /test . * unittest includes module level terraform plan validation test. It is required to implement the unit tests for each module. Make sure each test case covers default, customised and invalid conditions. * e2etest contains the end-to-end tests for infrastructure and products. It will follow the entire deployment process including provisioning resources into a cloud provider. Each product will have one test function that covers all the states. The test function starts with generating configuration for the terratest , helm , kubectl commands. You can change config variables as you like in the GenerateConfigForProductE2eTest() function. The provisioning process will be as follows: 1. Create AWS resources using Terraform 2. Create EKS namespace (product name by default) 3. Helm adds Atlassian helm chart repository and install specified product Once the cluster and product are initialised, assert functions will validate the terraform outputs. bamboo_test.go file will only test the resource creation and validation : You must run cleanup_test.go to test the destruction!","title":"Structure"},{"location":"development/HOW_TO_TEST/#requirements","text":"The repo uses Terratest for testing. The following are required to run the test: 1. install Terraform . E.g. brew install hashicorp/tap/terraform 2. install Go . E.g. brew install go 3. Set credentials to connect to cloud provider. The project looks for ~/.aws . For more details refer to AWS cli-configure-quickstart .","title":"Requirements:"},{"location":"development/HOW_TO_TEST/#how-to-run-unit-test","text":"cd test && go get -v -t -d ./... && go mod tidy go test ./unittest/... -v You can run test with regex keyword to run specific group of test cases e.g. Running only VPC module related tests go test./unittest/... -v -run TestVpc","title":"How to run unit test"},{"location":"development/HOW_TO_TEST/#how-to-run-end-to-end-test-approx-40-60-mins","text":"cd test && mkdir ./e2etest/artifacts go get -v -t -d ./... && go mod tidy go test ./e2etest -v -timeout 40m -run Bamboo | tee ./e2etest/artifacts/e2e-test.log Clean up test go test ./e2etest -v -timeout 40m -run Cleanup | tee ./e2etest/artifacts/e2e-test-cleanup.log","title":"How to run end-to-end test (approx. 40-60 mins)"},{"location":"development/HOW_TO_TEST/#how-to-reuse-end-to-end-test-environment","text":"When you run end-to-end test for the first time, the test function will create an environment config file under /test/e2etest/artifacts folder (the default file name is e2e_test_env_config.json ). This config file allows you to reuse the existing terraform environment directory created by terratest. You can specify the config file name on the second run and the function will load the config data and reuse the existing environment. e.g. go test ./e2etest -v -timeout 40m -run Bamboo -config=e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test.log You can do the same for the cleanup test. e.g. go test ./e2etest -v -timeout 40m -run Cleanup -config=e2e_test_env_config.json | tee ./e2etest/artifacts/e2e-test-cleanup.log If -config flag is not specified, the second test will create a new test environment and overwrite e2e_test_env_config.json if existed So make sure you rename e2e_test_env_config.json to avoid accidental overwrites.","title":"How to reuse end-to-end test environment"},{"location":"development/HOW_TO_TEST/#github-action","text":"GitHub action will run for unit and end-to-end tests. Config file is in .github/workflows","title":"GitHub Action"},{"location":"troubleshooting/LIMITATIONS/","text":"Limitations \u00b6 Product limitations \u00b6 At this time Bamboo Data Center is the only supported product by Terraform deployment. We have a plan to support more Atlassian Data Center products in the future. Infrastructure limitations \u00b6 Cloud Provider \u00b6 AWS Cloud provider is the only supported platform. Database \u00b6 Postgres is the defined database engine for the products and cannot be modified in the configuration. However, use can change the database instance type and storage size .","title":"Limitations"},{"location":"troubleshooting/LIMITATIONS/#limitations","text":"","title":"Limitations"},{"location":"troubleshooting/LIMITATIONS/#product-limitations","text":"At this time Bamboo Data Center is the only supported product by Terraform deployment. We have a plan to support more Atlassian Data Center products in the future.","title":"Product limitations"},{"location":"troubleshooting/LIMITATIONS/#infrastructure-limitations","text":"","title":"Infrastructure limitations"},{"location":"troubleshooting/LIMITATIONS/#cloud-provider","text":"AWS Cloud provider is the only supported platform.","title":"Cloud Provider"},{"location":"troubleshooting/LIMITATIONS/#database","text":"Postgres is the defined database engine for the products and cannot be modified in the configuration. However, use can change the database instance type and storage size .","title":"Database"},{"location":"troubleshooting/SUPPORT_BOUNDARIES/","text":"Support boundaries \u00b6 This page describes what is within our scope of support for Terraform data center deployments, and what isn't. Additional information Read our troubleshooting tips . Read about the product and platform limitations .","title":"Support boundaries"},{"location":"troubleshooting/SUPPORT_BOUNDARIES/#support-boundaries","text":"This page describes what is within our scope of support for Terraform data center deployments, and what isn't. Additional information Read our troubleshooting tips . Read about the product and platform limitations .","title":"Support boundaries"},{"location":"troubleshooting/TROUBLESHOOTING/","text":"Troubleshooting tips \u00b6 This guide contains general tips on how to investigate an application deployment that doesn't work correctly. Cleanup Terraform state \u00b6 Terraform stores the lock and current state in the terraform backend file in terraform-backend.tf . This file will be generated by the install process based on the content of config.auto.tfvars . If the user changes some key configuration items such as region or environment_name then you should cleanup all temporary files generated by terraform and install modules again. To cleanup the local terraform files, run the following command: ./pkg/scripts/cleanup.sh AWS Access \u00b6 Symptom \u00b6 Terraform uses 'config.tfvars' to install the infrastructure. Verifying the config file. Cleaning all the generated terraform state variable and backend file. ngh-bamboo' infrastructure deployment is started using config.tfvars. Terraform state backend/variable files are missing. An error occurred (ExpiredToken) when calling the GetCallerIdentity operation: The security token included in the request is expired Solution \u00b6 Terraform cannot deploy resources into the AWS cloud if your security token has expired. You will need to renew your token and retry. How to unlock terraform \u00b6 If user interrupts the execution of install or uninstall actions, Terraform never get a chance to unlock the locked resources. In this case Terraform cannot capture the lock in next attempt. Symptom \u00b6 Acquiring state lock. This may take a few moments... Error: Error acquiring the state lock Error message: ConditionalCheckFailedException: The conditional request failed Lock Info: ID: 26f7b9a8-4bef-0674-669b-1d90800dea4d Path: atlassian-data-center-terraform-state-xxxxxxxxxx/bamboo-xxxxxxxxxx/terraform.tfstate Operation: OperationTypeApply Who: nghazalibeiklar@C02CK0JYMD6V Version: 1.0.9 Created: 2021-11-04 00:50:34.736134 +0000 UTC Info: Terraform acquires a state lock to protect the state from being written by multiple users at the same time. Please resolve the issue above and try again. For most commands, you can disable locking with the \"-lock=false\" flag, but this is not recommended. Solution \u00b6 To fix this you need to unlock state first by running the following command (replace ID with the value from the error message): terraform force-unlock <ID> Are you still having the lock problem after running terraform force-unlock ? There are two terraform locks, one for infrastructure and another for terraform state. If running the following command from repo folder does not unlock the resources, then change the current path to ./pkg/tfstate and retry the same command.","title":"Troubleshooting tips"},{"location":"troubleshooting/TROUBLESHOOTING/#troubleshooting-tips","text":"This guide contains general tips on how to investigate an application deployment that doesn't work correctly.","title":"Troubleshooting tips"},{"location":"troubleshooting/TROUBLESHOOTING/#cleanup-terraform-state","text":"Terraform stores the lock and current state in the terraform backend file in terraform-backend.tf . This file will be generated by the install process based on the content of config.auto.tfvars . If the user changes some key configuration items such as region or environment_name then you should cleanup all temporary files generated by terraform and install modules again. To cleanup the local terraform files, run the following command: ./pkg/scripts/cleanup.sh","title":"Cleanup Terraform state"},{"location":"troubleshooting/TROUBLESHOOTING/#aws-access","text":"","title":"AWS Access"},{"location":"troubleshooting/TROUBLESHOOTING/#symptom","text":"Terraform uses 'config.tfvars' to install the infrastructure. Verifying the config file. Cleaning all the generated terraform state variable and backend file. ngh-bamboo' infrastructure deployment is started using config.tfvars. Terraform state backend/variable files are missing. An error occurred (ExpiredToken) when calling the GetCallerIdentity operation: The security token included in the request is expired","title":"Symptom"},{"location":"troubleshooting/TROUBLESHOOTING/#solution","text":"Terraform cannot deploy resources into the AWS cloud if your security token has expired. You will need to renew your token and retry.","title":"Solution"},{"location":"troubleshooting/TROUBLESHOOTING/#how-to-unlock-terraform","text":"If user interrupts the execution of install or uninstall actions, Terraform never get a chance to unlock the locked resources. In this case Terraform cannot capture the lock in next attempt.","title":"How to unlock terraform"},{"location":"troubleshooting/TROUBLESHOOTING/#symptom_1","text":"Acquiring state lock. This may take a few moments... Error: Error acquiring the state lock Error message: ConditionalCheckFailedException: The conditional request failed Lock Info: ID: 26f7b9a8-4bef-0674-669b-1d90800dea4d Path: atlassian-data-center-terraform-state-xxxxxxxxxx/bamboo-xxxxxxxxxx/terraform.tfstate Operation: OperationTypeApply Who: nghazalibeiklar@C02CK0JYMD6V Version: 1.0.9 Created: 2021-11-04 00:50:34.736134 +0000 UTC Info: Terraform acquires a state lock to protect the state from being written by multiple users at the same time. Please resolve the issue above and try again. For most commands, you can disable locking with the \"-lock=false\" flag, but this is not recommended.","title":"Symptom"},{"location":"troubleshooting/TROUBLESHOOTING/#solution_1","text":"To fix this you need to unlock state first by running the following command (replace ID with the value from the error message): terraform force-unlock <ID> Are you still having the lock problem after running terraform force-unlock ? There are two terraform locks, one for infrastructure and another for terraform state. If running the following command from repo folder does not unlock the resources, then change the current path to ./pkg/tfstate and retry the same command.","title":"Solution"},{"location":"userguide/CLEANUP/","text":"Uninstall and Cleanup \u00b6 You may lose valuable data in the cleanup process Before you start uninstalling the products and infrastructure make sure you have backed up all data you may need. After uninstall you have no access to the product data including local volume, shared volume, database, and Terraform state information. To uninstall the products and clean up the infrastructure first make sure you made a backup from all application data you may need. Uninstall will permanently delete the database, shared home, local home, and Terraform state data. If you wish to uninstall just one product please do not proceed with the uninstall process and see Configuration instead. Make sure you have made backup of the product data. All product data will be permanently deleted after uninstall. You may proceed when you are ready to uninstall: In order to uninstall the products and cleanup the infrastructure, you need to have the same configuration file that you used to install the infrastructure. If you have used the default configuration file ( config.auto.tfvars ) from the root folder of the project, then you may simply use the following command: ./pkg/scripts/uninstall If you used a custom config file to install the infrastructure then you need to run the following command instead: ./pkg/scripts/uninstall -c <custom-config-file> This will remove the products and all Atlassian Data Center infrastructure including Terraform state which were created by the installing process. Do you want to keep the terraform state? If you want to keep the terraform state files and dynamodb lock table then use the switch -s : ./pkg/scripts/uninstall -s [ -c <custom-config-file> ]","title":"Uninstall and Cleanup"},{"location":"userguide/CLEANUP/#uninstall-and-cleanup","text":"You may lose valuable data in the cleanup process Before you start uninstalling the products and infrastructure make sure you have backed up all data you may need. After uninstall you have no access to the product data including local volume, shared volume, database, and Terraform state information. To uninstall the products and clean up the infrastructure first make sure you made a backup from all application data you may need. Uninstall will permanently delete the database, shared home, local home, and Terraform state data. If you wish to uninstall just one product please do not proceed with the uninstall process and see Configuration instead. Make sure you have made backup of the product data. All product data will be permanently deleted after uninstall. You may proceed when you are ready to uninstall: In order to uninstall the products and cleanup the infrastructure, you need to have the same configuration file that you used to install the infrastructure. If you have used the default configuration file ( config.auto.tfvars ) from the root folder of the project, then you may simply use the following command: ./pkg/scripts/uninstall If you used a custom config file to install the infrastructure then you need to run the following command instead: ./pkg/scripts/uninstall -c <custom-config-file> This will remove the products and all Atlassian Data Center infrastructure including Terraform state which were created by the installing process. Do you want to keep the terraform state? If you want to keep the terraform state files and dynamodb lock table then use the switch -s : ./pkg/scripts/uninstall -s [ -c <custom-config-file> ]","title":"Uninstall and Cleanup"},{"location":"userguide/CONFIGURATION/","text":"Configuration \u00b6 In order to create the infrastructure and install the product you need to configure the terraform project. All configuration data should go to a terraform variable file. The content of the config file is divided into two groups: Mandatory configuration Optional configuration Configuration file format. The config file is an ASCII text file with .tfvars extension. The config file should contain all mandatory configuration items with valid values. Optional items can be part of the content. If any optional item is missing, the default value will be applied. The mandatory configuration items are those you should define once before the first installation, and you cannot change them in the entire environment lifecycle. However, the optional configuration part applies to those items that are not required for installation by default, but you can define and override the default value. The optional configuration may change anytime in the life cycle of the environment. Terraform will keep the latest status of the environment and use it for any further change you make later. An example of config file for terraform project: Here is a sample of a configuration file for the project. # Mandatory items environment_name = \"my-bamboo-env\" region = \"us-east-2\" # Optional items resource_tags = { Terraform : \"true\" , Organization : \"atlassian\" , product : \"bamboo\" , } instance_types = [ \"m5.xlarge\" ] desired_capacity = 2 domain = \"mydomain.com\" Mandatory configuration \u00b6 Environment Name \u00b6 environment_name provides your environment a unique name within a single cloud provider account. This value cannot be altered after the configuration has been applied. The value will be used to form the name of some resources including vpc and Kubernetes cluster . environment_name = \"<YOUR-ENVIRONMENT-NAME>\" Environment names should start with an alphabet character and could contain alphabet, numbers and dash - . The length of the environment_name value cannot exceed 17 characters. Region \u00b6 region defines the cloud provider region that this configuration will deploy to. This value should be a valid AWS region . region = \"<Region>\" # e.g: \"ap-northeast-2\" Optional configuration \u00b6 Resource Tags \u00b6 resource_tags are the custom tags for all resources to be created in the environment. Tag names should be unique. You can add all tags you need to propagate among the resources as a list. Resource tags are optional. resource_tags = { <tag-name- 0 > : \"<tag-value>\" , <tag-name- 1 > : \"<tag-value>\" , ... <tag-name-n> : \"<tag-value>\" , } Cluster Instance Type \u00b6 instance_types provides the instance types for the Kubernetes cluster node group. The default value for this would be m5.xlarge if it is not defined in the config file. Instance type should be a valid AWS instance type . instance_types = [ \"instance-type\"] # e.g: [\"m5.2xlarge\" ] Cluster Size \u00b6 desired_capacity provides the desired number of nodes that the node group should launch with initially. The default value for the number of nodes in Kubernetes node groups is 1 . Minimum is 1 and maximum is 10 . desired_capacity = < number -of-nodes> # between 1 and 10 Domain Name \u00b6 It is highly recommended to use a domain name and access the application via HTTPS protocol. You will be required to secure a domain name and supply the configuration to the config file. When the domain is provided, Terraform will create a Route53 hosted zone based on the environment name. Final domain will have the following format: <product>.<environment-name>.<domain-name> . For example bamboo.staging.mydomain.com . domain = \"<domain-name>\" # for example: \"mydomain.com\" Removing domain from deployment If you have deployed with domain, you cannot remove the domain later from the deployment to revert to an unsecured deployment running on HTTP (see below). Ingress Controller When the domain is used, Terraform will create nginx-ingress controller in the EKS cluster that will provide access to the application via the domain name. It also creates an ACM certificate that is ensuring access over secure HTTPS protocol. Provisioning without domain name \u00b6 You can provision the infrastructure without a domain name. To do that, you can comment out the domain variable in the tfvars file. In that case the application will run unsecured on an elastic load balancer domain: http://<load-balancer-id>.<region>.elb.amazonaws.com . The final URL is printed out as part of the outputs after the infrastructure is provisioned. Database Instance Class \u00b6 db_instance_class sets the DB instance type that allocates the computational, network, and memory capacity required by planned workload of the DB instance. Detailed available instance classes can be found via AWS RDS documentation on DB Instance Class . db_instance_class = \"<instance.class>\" # e.g. \"db.t3.micro\" Database Allocated Storage \u00b6 db_allocated_storage sets the allocated storage for database instance in GiB. Note: the allowed value range of allocated storage may vary based on instance class. You may want to adjust these values according to your needs. Documentation can be found via: AWS RDS documentation on Storage . db_allocated_storage = 100 Database IOPS \u00b6 db_iops sets the requested number of I/O operations per second that the DB instance can support. Note: the allowed value range of IOPS may vary based on instance class. You may want to adjust these values according to your needs. Documentation can be found via: AWS RDS documentation on Storage . db_iops = 1000","title":"Configuration"},{"location":"userguide/CONFIGURATION/#configuration","text":"In order to create the infrastructure and install the product you need to configure the terraform project. All configuration data should go to a terraform variable file. The content of the config file is divided into two groups: Mandatory configuration Optional configuration Configuration file format. The config file is an ASCII text file with .tfvars extension. The config file should contain all mandatory configuration items with valid values. Optional items can be part of the content. If any optional item is missing, the default value will be applied. The mandatory configuration items are those you should define once before the first installation, and you cannot change them in the entire environment lifecycle. However, the optional configuration part applies to those items that are not required for installation by default, but you can define and override the default value. The optional configuration may change anytime in the life cycle of the environment. Terraform will keep the latest status of the environment and use it for any further change you make later. An example of config file for terraform project: Here is a sample of a configuration file for the project. # Mandatory items environment_name = \"my-bamboo-env\" region = \"us-east-2\" # Optional items resource_tags = { Terraform : \"true\" , Organization : \"atlassian\" , product : \"bamboo\" , } instance_types = [ \"m5.xlarge\" ] desired_capacity = 2 domain = \"mydomain.com\"","title":"Configuration"},{"location":"userguide/CONFIGURATION/#mandatory-configuration","text":"","title":"Mandatory configuration"},{"location":"userguide/CONFIGURATION/#environment-name","text":"environment_name provides your environment a unique name within a single cloud provider account. This value cannot be altered after the configuration has been applied. The value will be used to form the name of some resources including vpc and Kubernetes cluster . environment_name = \"<YOUR-ENVIRONMENT-NAME>\" Environment names should start with an alphabet character and could contain alphabet, numbers and dash - . The length of the environment_name value cannot exceed 17 characters.","title":"Environment Name"},{"location":"userguide/CONFIGURATION/#region","text":"region defines the cloud provider region that this configuration will deploy to. This value should be a valid AWS region . region = \"<Region>\" # e.g: \"ap-northeast-2\"","title":"Region"},{"location":"userguide/CONFIGURATION/#optional-configuration","text":"","title":"Optional configuration"},{"location":"userguide/CONFIGURATION/#resource-tags","text":"resource_tags are the custom tags for all resources to be created in the environment. Tag names should be unique. You can add all tags you need to propagate among the resources as a list. Resource tags are optional. resource_tags = { <tag-name- 0 > : \"<tag-value>\" , <tag-name- 1 > : \"<tag-value>\" , ... <tag-name-n> : \"<tag-value>\" , }","title":"Resource Tags"},{"location":"userguide/CONFIGURATION/#cluster-instance-type","text":"instance_types provides the instance types for the Kubernetes cluster node group. The default value for this would be m5.xlarge if it is not defined in the config file. Instance type should be a valid AWS instance type . instance_types = [ \"instance-type\"] # e.g: [\"m5.2xlarge\" ]","title":"Cluster Instance Type"},{"location":"userguide/CONFIGURATION/#cluster-size","text":"desired_capacity provides the desired number of nodes that the node group should launch with initially. The default value for the number of nodes in Kubernetes node groups is 1 . Minimum is 1 and maximum is 10 . desired_capacity = < number -of-nodes> # between 1 and 10","title":"Cluster Size"},{"location":"userguide/CONFIGURATION/#domain-name","text":"It is highly recommended to use a domain name and access the application via HTTPS protocol. You will be required to secure a domain name and supply the configuration to the config file. When the domain is provided, Terraform will create a Route53 hosted zone based on the environment name. Final domain will have the following format: <product>.<environment-name>.<domain-name> . For example bamboo.staging.mydomain.com . domain = \"<domain-name>\" # for example: \"mydomain.com\" Removing domain from deployment If you have deployed with domain, you cannot remove the domain later from the deployment to revert to an unsecured deployment running on HTTP (see below). Ingress Controller When the domain is used, Terraform will create nginx-ingress controller in the EKS cluster that will provide access to the application via the domain name. It also creates an ACM certificate that is ensuring access over secure HTTPS protocol.","title":"Domain Name"},{"location":"userguide/CONFIGURATION/#provisioning-without-domain-name","text":"You can provision the infrastructure without a domain name. To do that, you can comment out the domain variable in the tfvars file. In that case the application will run unsecured on an elastic load balancer domain: http://<load-balancer-id>.<region>.elb.amazonaws.com . The final URL is printed out as part of the outputs after the infrastructure is provisioned.","title":"Provisioning without domain name"},{"location":"userguide/CONFIGURATION/#database-instance-class","text":"db_instance_class sets the DB instance type that allocates the computational, network, and memory capacity required by planned workload of the DB instance. Detailed available instance classes can be found via AWS RDS documentation on DB Instance Class . db_instance_class = \"<instance.class>\" # e.g. \"db.t3.micro\"","title":"Database Instance Class"},{"location":"userguide/CONFIGURATION/#database-allocated-storage","text":"db_allocated_storage sets the allocated storage for database instance in GiB. Note: the allowed value range of allocated storage may vary based on instance class. You may want to adjust these values according to your needs. Documentation can be found via: AWS RDS documentation on Storage . db_allocated_storage = 100","title":"Database Allocated Storage"},{"location":"userguide/CONFIGURATION/#database-iops","text":"db_iops sets the requested number of I/O operations per second that the DB instance can support. Note: the allowed value range of IOPS may vary based on instance class. You may want to adjust these values according to your needs. Documentation can be found via: AWS RDS documentation on Storage . db_iops = 1000","title":"Database IOPS"},{"location":"userguide/INSTALLATION/","text":"Installation \u00b6 List of supported Atlassian Data Center products. At this time Bamboo DC is the only supported product by this project. We will work hard to include more Data Center products into this project. 1. AWS Configuration \u00b6 Configure your AWS credentials with admin access. AWS Documentation 2. Clone the project \u00b6 Clone the Terraform for Atlassian DC Products into your local git clone https://github.com/atlassian-labs/data-center-terraform.git && cd data-center-terraform 3. Configure the infrastructure \u00b6 Configure the infrastructure for the selected products. Open configuration file using a text editor and configure the infrastructure as required (See configuration page). Where to find the configuration file? The Terraform project uses config.auto.tfvars from root to configure the infrastructure in install and uninstall process by default. How to use a different configuration file? You can use any other customised file with the same format as default config file to override it. This could be done by making a copy of config.auto.tfvars and use it as a template to define the configuration of your infrastructure. Then use this file to override the default config file in install and uninstall steps. Make sure you use the same configuration file in both install and uninstall of the infrastructure. If you have more than one environment, make sure to manage the config file of each environment separately. When you need to clean up the environment use the same config file that is being used to create the environment. 4. Install the infrastructure and product \u00b6 When based on your environment the config file is configured then you are ready to start installation process. Installing process will provision the required infrastructure for the configured environment and will install the selected products. Terraform handles creating and managing the infrastructure. To keep track of the current state of the resources and manage any further change, terraform creates a S3 bucket to store the current state of the environment. Also, it creates a dynamodb table to handle to manage lock the environment during installation, cleanup, and upgrade to prevent modifying by more than one process at the time. This process is part of installation and no extra step is needed to take. The installation script is located in pkg/scripts folder of the project. Usage: ./pkg/scripts/install.sh [-c <config-file] [-h] As mentioned before, the default config file is config.auto.tfvars and located in root of the project. Running install script with no parameter will use the default config file to provision the environment. You may use a different file with the same format to handle more than one environment but remember when you want to uninstall and cleanup the environment you need use the same config file. Supported Atlassian Data Center products. At this time Bamboo is the only supported product. Using the default config file To provision the infrastructure using default config file run: ./pkg/scripts/install.sh Using other config file If you need to use a different config file other than the defualt one then first create and configure your config file and then run: ./pkg/scripts/install.sh -c <your-config_file> How to run the product after installation? When the installation process finishes successfully, you can find some detailed information about the infrastructure on your console including the endpoint url ( product_urls / load_balancer_hostname ) to open the product on your browser and more. How to find the database username and password? Database master username and password for each product are generated by Terraform and pushed in the Terraform secret in the product namespace. To access to the database username and password run the following commands: DB_SECRETS=$(kubectl get secret <product-name>-db-cred -n <product-name> -o jsonpath='{.data}') DB_USERNAME=$(echo $DB_SECRETS | jq -r '.username' | base64 --decode) DB_PASSWORD=$(echo $DB_SECRETS | jq -r '.password' | base64 --decode) This will give you decoded username and password stored in $DB_USERNAME and $DB_PASSWORD environment variables.","title":"Installation"},{"location":"userguide/INSTALLATION/#installation","text":"List of supported Atlassian Data Center products. At this time Bamboo DC is the only supported product by this project. We will work hard to include more Data Center products into this project.","title":"Installation"},{"location":"userguide/INSTALLATION/#1-aws-configuration","text":"Configure your AWS credentials with admin access. AWS Documentation","title":"1. AWS Configuration"},{"location":"userguide/INSTALLATION/#2-clone-the-project","text":"Clone the Terraform for Atlassian DC Products into your local git clone https://github.com/atlassian-labs/data-center-terraform.git && cd data-center-terraform","title":"2. Clone the project"},{"location":"userguide/INSTALLATION/#3-configure-the-infrastructure","text":"Configure the infrastructure for the selected products. Open configuration file using a text editor and configure the infrastructure as required (See configuration page). Where to find the configuration file? The Terraform project uses config.auto.tfvars from root to configure the infrastructure in install and uninstall process by default. How to use a different configuration file? You can use any other customised file with the same format as default config file to override it. This could be done by making a copy of config.auto.tfvars and use it as a template to define the configuration of your infrastructure. Then use this file to override the default config file in install and uninstall steps. Make sure you use the same configuration file in both install and uninstall of the infrastructure. If you have more than one environment, make sure to manage the config file of each environment separately. When you need to clean up the environment use the same config file that is being used to create the environment.","title":"3. Configure the infrastructure"},{"location":"userguide/INSTALLATION/#4-install-the-infrastructure-and-product","text":"When based on your environment the config file is configured then you are ready to start installation process. Installing process will provision the required infrastructure for the configured environment and will install the selected products. Terraform handles creating and managing the infrastructure. To keep track of the current state of the resources and manage any further change, terraform creates a S3 bucket to store the current state of the environment. Also, it creates a dynamodb table to handle to manage lock the environment during installation, cleanup, and upgrade to prevent modifying by more than one process at the time. This process is part of installation and no extra step is needed to take. The installation script is located in pkg/scripts folder of the project. Usage: ./pkg/scripts/install.sh [-c <config-file] [-h] As mentioned before, the default config file is config.auto.tfvars and located in root of the project. Running install script with no parameter will use the default config file to provision the environment. You may use a different file with the same format to handle more than one environment but remember when you want to uninstall and cleanup the environment you need use the same config file. Supported Atlassian Data Center products. At this time Bamboo is the only supported product. Using the default config file To provision the infrastructure using default config file run: ./pkg/scripts/install.sh Using other config file If you need to use a different config file other than the defualt one then first create and configure your config file and then run: ./pkg/scripts/install.sh -c <your-config_file> How to run the product after installation? When the installation process finishes successfully, you can find some detailed information about the infrastructure on your console including the endpoint url ( product_urls / load_balancer_hostname ) to open the product on your browser and more. How to find the database username and password? Database master username and password for each product are generated by Terraform and pushed in the Terraform secret in the product namespace. To access to the database username and password run the following commands: DB_SECRETS=$(kubectl get secret <product-name>-db-cred -n <product-name> -o jsonpath='{.data}') DB_USERNAME=$(echo $DB_SECRETS | jq -r '.username' | base64 --decode) DB_PASSWORD=$(echo $DB_SECRETS | jq -r '.password' | base64 --decode) This will give you decoded username and password stored in $DB_USERNAME and $DB_PASSWORD environment variables.","title":"4. Install the infrastructure and product"},{"location":"userguide/PREREQUISITES/","text":"Prerequisites \u00b6 Requirements \u00b6 In order to deploy Atlassian\u2019s Data Center infrastructure, the following are required: An understanding of Kubernetes and Helm concepts. An understanding of Terraform . An AWS account with admin access. Environment setup \u00b6 Before installing you need to make sure your environment has the necessary tools:: Install Terraform Install helm v3.3 or later Install AWS CLI Kubernetes tools (optional) Terraform \u00b6 Terraform is an open source infrastructure as code that provides a consistent CLI workflow to create and manage infrastructures on the cloud environment. We use terraform in this project to create and manage Atlassian Data Center infrastructure on AWS cloud to be used with the supported Data Center products. Currently, not all Data Center products are supported. At this stage Bamboo is the only supported product. Please make sure to install the latest version of Terraform Helm \u00b6 Atlassian supports Helm Charts for some of Data Center products including Bamboo. This project uses terraform to provision the infrastructure for Atlassian products and uses the Helm charts to install them as a turnkey solution. Before using this project make sure you have Helm v3.3 or later installed on your machine. How to confirm your Helm version? Use the following command to see the installed Helm version on your local: helm version --short If you have not installed Helm on your local environment, or the installed version is lower than v3.3 then you need to install Helm . AWS CLI \u00b6 You need to have the AWS CLI tool installed on your local machine before installing the infrastructure. We recommend having version 2 of aws-cli . aws --version If you still have no AWS CLI installed on your local environment please install it before proceeding to the next step. Kubernetes tools \u00b6 This step is not mandatory in order to use Terraform for Atlassian Data Center products, but we recommend you to have some useful tools such as kubectl to be able monitor and diagnose the resources in the Kubernetes cluster. Other useful tools There are many Kubernetes open source monitoring tools such as Prometheus , Grafana , Weave Scope , and many other tools that could be useful.","title":"Prerequisites"},{"location":"userguide/PREREQUISITES/#prerequisites","text":"","title":"Prerequisites"},{"location":"userguide/PREREQUISITES/#requirements","text":"In order to deploy Atlassian\u2019s Data Center infrastructure, the following are required: An understanding of Kubernetes and Helm concepts. An understanding of Terraform . An AWS account with admin access.","title":"Requirements"},{"location":"userguide/PREREQUISITES/#environment-setup","text":"Before installing you need to make sure your environment has the necessary tools:: Install Terraform Install helm v3.3 or later Install AWS CLI Kubernetes tools (optional)","title":"Environment setup"},{"location":"userguide/PREREQUISITES/#terraform","text":"Terraform is an open source infrastructure as code that provides a consistent CLI workflow to create and manage infrastructures on the cloud environment. We use terraform in this project to create and manage Atlassian Data Center infrastructure on AWS cloud to be used with the supported Data Center products. Currently, not all Data Center products are supported. At this stage Bamboo is the only supported product. Please make sure to install the latest version of Terraform","title":" Terraform"},{"location":"userguide/PREREQUISITES/#helm","text":"Atlassian supports Helm Charts for some of Data Center products including Bamboo. This project uses terraform to provision the infrastructure for Atlassian products and uses the Helm charts to install them as a turnkey solution. Before using this project make sure you have Helm v3.3 or later installed on your machine. How to confirm your Helm version? Use the following command to see the installed Helm version on your local: helm version --short If you have not installed Helm on your local environment, or the installed version is lower than v3.3 then you need to install Helm .","title":" Helm"},{"location":"userguide/PREREQUISITES/#aws-cli","text":"You need to have the AWS CLI tool installed on your local machine before installing the infrastructure. We recommend having version 2 of aws-cli . aws --version If you still have no AWS CLI installed on your local environment please install it before proceeding to the next step.","title":" AWS CLI"},{"location":"userguide/PREREQUISITES/#kubernetes-tools","text":"This step is not mandatory in order to use Terraform for Atlassian Data Center products, but we recommend you to have some useful tools such as kubectl to be able monitor and diagnose the resources in the Kubernetes cluster. Other useful tools There are many Kubernetes open source monitoring tools such as Prometheus , Grafana , Weave Scope , and many other tools that could be useful.","title":" Kubernetes tools"},{"location":"userguide/UPGRADE/","text":"Upgrade \u00b6","title":"Upgrade"},{"location":"userguide/UPGRADE/#upgrade","text":"","title":"Upgrade"},{"location":"userguide/VERSIONING/","text":"Versioning \u00b6 Release naming \u00b6 Each product version is semantically versioned . Version name will be defined by the following pattern: tf-dc-MAJOR.MINOR.PATCH , e.g. tf-dc-0.0.1 . Release versions \u00b6 The version number for first release starts from 0.0.1 and next release versions will be defined based on the nature of the delivered changes: If there is at least one change that breaks upgrading from the previous version (backwards incompatible), then the next version will be the next MAJOR version. If at least one functional change is delivered and all changes are backward compatible, then the next release will be the next MINOR version. Any other backward compatible bug fix will be in the next PATCH version. Breaking changes Any backwards-incompatible changes to the infrastructure should bump the MAJOR version.","title":"Versioning"},{"location":"userguide/VERSIONING/#versioning","text":"","title":"Versioning"},{"location":"userguide/VERSIONING/#release-naming","text":"Each product version is semantically versioned . Version name will be defined by the following pattern: tf-dc-MAJOR.MINOR.PATCH , e.g. tf-dc-0.0.1 .","title":"Release naming"},{"location":"userguide/VERSIONING/#release-versions","text":"The version number for first release starts from 0.0.1 and next release versions will be defined based on the nature of the delivered changes: If there is at least one change that breaks upgrading from the previous version (backwards incompatible), then the next version will be the next MAJOR version. If at least one functional change is delivered and all changes are backward compatible, then the next release will be the next MINOR version. Any other backward compatible bug fix will be in the next PATCH version. Breaking changes Any backwards-incompatible changes to the infrastructure should bump the MAJOR version.","title":"Release versions"}]}